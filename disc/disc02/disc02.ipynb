{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Matters\n",
    "\n",
    "### Striving for Representativeness\n",
    "\n",
    "*Data quality* is an important consideration for any data scientist. Quality includes tidyness, trustworthiness, completeness, and so on. The overall *goal* of data quality, however, is to achieve an accurate representation of some real world construct. Hence, when the data comes from a sample of a population, we also consider *representativeness* as a key aspect of data quality, one which often requires careful reasoning.\n",
    "\n",
    "### Example - A Big Data Fail\n",
    "\n",
    "Consider the 1936 federal presidential election of FDR vs Al Landon. The magazine *Literary Digest*'s straw poll had correctly predicted the outcome of the previous five presidential elections. Running up to the election, they polled over $10$ million individuals including\n",
    "    - magazine subscribers\n",
    "    - registered automobile owners\n",
    "    - telephone owners\n",
    "and received responses from about $2.4$ million of those polled. The *Literary Digest* predicted Landon would win in a landslide. By contrast, George Gallup's quota sample consisted of bi-weekly surveys of $2000$ individuals, and correctly predicted a landslide for FDR. \n",
    "\n",
    "<img src=\"qmark.svg\" width=\"30\" align=\"left\"> **Question:** what are some potential sources of bias in each of these polling schemes? \n",
    "\n",
    "Soln. Possible Answers (elaborate // discuss)\n",
    "    - non-response bias\n",
    "    - sampling bias\n",
    "    - reporting bias\n",
    "    \n",
    "    \n",
    "### Breakdown of Types\n",
    "    - census\n",
    "    - sample\n",
    "        - random\n",
    "            - simple random \n",
    "            - stratified\n",
    "            - cluster \n",
    "            - size-weighted\n",
    "        - non-random\n",
    "            - convenience \n",
    "            - snowball or referral \n",
    "            - quota \n",
    "\n",
    "<!---\n",
    "\n",
    "## Simple Random Sample (SRS)\n",
    "\n",
    "Given $N$ subjects labelled $\\{1,\\dots,N\\}$, a *SRS* of size $n\\le N$ is a random subset of $n$ subjects $A\\subseteq \\{1,\\dots,N\\}$ such that observing any subset of $n$ subjects is equally likely. There are ${N\\choose n}$ subsets of size $n$, so a SRS satisfies \n",
    "$$\n",
    "\\mathbb P\\left(A = A_0\\right) =  \\frac{1}{{N\\choose n}},\n",
    "$$\n",
    "for any subset $A_0\\subseteq\\{1,\\dots,N\\}$ with $n$ elements.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Considerations\n",
    "\n",
    "If your dataset is too big...\n",
    "\n",
    "- You can run out of patience to wait for something to finish running.\n",
    "- You can run out of memory on one computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule of Thumb for Computation Time\n",
    "\n",
    "Usually, Python running on a machine in 2017 can run about 10,000,000 additions per second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# The timeit Jupyter magic command will run this cell several times, timing each run\n",
    "\n",
    "additions = 10000000 # 10 million\n",
    "\n",
    "to_add_1 = 1234567890\n",
    "to_add_2 = 987654321\n",
    "\n",
    "for _ in range(additions):\n",
    "    to_add_1 + to_add_2\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out this website on your own time: https://computers-are-fast.github.io/.\n",
    "\n",
    "Having a sense of how long things will take helps you a lot when trying to figure out whether you can just wait for something to finish vs. whether you should think of another solution (eg. better algorithm, distributed computing, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain a SRS with Python\n",
    "\n",
    "Some methods have different runtimes than others. Let's compare `np.random.choice` and Python's built-in `random.sample`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "N = 50000\n",
    "n = 100\n",
    "\n",
    "# using numpy - returns an array of shape (n,)\n",
    "np.random.choice(range(N),n,replace=False)\n",
    "\n",
    "# using random module - returns a list of length n\n",
    "random.sample(range(N),n)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wall-Clock Time Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = [100,200,300,400,500,1000,2000,3000,4000,5000]\n",
    "t0 = []\n",
    "t1 = []\n",
    "\n",
    "for n in nn:\n",
    "    t0.append(timeit(setup=\"import numpy as np\",\n",
    "                     stmt=\"np.random.choice(a=range(5000),size=%d,replace=False)\" % n,\n",
    "                     number=500))\n",
    "\n",
    "    t1.append(timeit(setup=\"import random\",\n",
    "                     stmt=\"random.sample(range(5000),%d)\" % n,\n",
    "                     number=500))\n",
    "\n",
    "plt.plot(nn,t0)\n",
    "plt.plot(nn,t1)\n",
    "plt.xlabel(\"Sample Size $n$\")\n",
    "plt.ylabel(\"Time $t$\")\n",
    "plt.title(\"Time to form a SRS from a Population of $N=5000$\")\n",
    "plt.legend([\"np.random.choice\",\"random.sample\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"qmark.svg\" width=\"30\" align=\"left\"> **Question:** What do you notice about this plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale of the SRS\n",
    "\n",
    "In the Powerball, there are $N=69$ white balls in a cage, numbered $1$ through $69$, and in the first part of the lottery, $n=5$ are sampled without replacement by repeatedly sampling a white ball uniformly from the remaining subset.\n",
    "\n",
    "<img src=\"qmark.svg\" width=\"30\" align=\"left\"> **Question:** How likely is each subset of five balls?\n",
    "\n",
    "Soln.\n",
    "$$\n",
    "{N\\choose n} = \\frac{69!}{5!\\cdot64!} = \\frac{69\\cdots 65}{5!} = 11,238,513\n",
    "$$\n",
    "\n",
    "In lecture, we looked at samples of $n=400$ women in the US aged $40$-$44$, a population of $N=8700000$ individuals (luckily, we knew ahead of time the fraction of such women with $1,2,3,$ or $4$ children). Now the number of possible subsets is\n",
    "$$\n",
    "{N\\choose n} \\approx 9.94 \\cdot 10^{1906}.\n",
    "$$\n",
    "\n",
    "### Big populations\n",
    "\n",
    "<img src=\"qmark.svg\" width=\"30\" align=\"left\"> **Question:** How would you simulate a sample of size 400 from the population of US women in Python? Is this feasible to do?\n",
    "\n",
    "<img src=\"qmark.svg\" width=\"30\" align=\"left\"> **Question:** Facebook generates about 2.7 billion Likes a day. That means there are about 1 trillion likes per year. How would you take a sample from their Likes database? Is this feasible to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservoir Sampling\n",
    "\n",
    "In some applications requiring a SRS, the size of the population $N$ is not known beforehand or is expensive to compute. The population can be read sequentially, say as lines in a csv file, but the file is too big to load into memory (eg. Facebook's database). Counting the lines $N$ would require its own pass through the lines of the file. Fortunately, there's a clever way to obtain a SRS in one pass over the data even when the size of the population is unknown.\n",
    "\n",
    "https://www.wikiwand.com/en/Reservoir_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def reservoir_sample(iterator, n):\n",
    "    sample, N = [], 0 # initialize\n",
    "    for item in iterator:\n",
    "        N += 1\n",
    "        # take the first n elements automatically\n",
    "        if len(sample) < n: \n",
    "            sample.append(item)\n",
    "        # add the next element to a random position s if s < n\n",
    "        else:\n",
    "            s = random.randint(0,N-1)\n",
    "            if s < n:\n",
    "                sample[s] = item\n",
    "        print(sample)\n",
    "        print(item)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that this makes each subset equally likely in a small example\n",
    "from collections import Counter\n",
    "tag = lambda x: 2**x[0] + 2**x[1]\n",
    "\n",
    "S = 1000000\n",
    "samples = [tuple(sorted(reservoir_sample([1,2,3,4],2))) for _ in range(S)]\n",
    "Counter(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Sampling for Attributes\n",
    "\n",
    "This material is optional and is intended for students with more background in probability. These ideas are essential for understanding how different sampling schemes work, but won't be tested (until perhaps a later course).\n",
    "\n",
    "### SRS\n",
    "Suppose we have a single Urn with $N$ balls which are identical but for their color, with $N_R < N$ of them red and $N_G = N-N_R$ of them green. Suppose we sample $n$ balls from the urn without replacement and observe exactly $x\\in\\{0,\\dots,n\\}$ red balls. There were $N_R$ red balls to choose the $x$ from, and $N_G$ green balls to choose the remaining $n-x$ from, so there are ${N_R\\choose x} {N_G\\choose n-x}$ possible subsets with exactly $x$ red balls. Since there are ${N\\choose n}$ possible subsets, each of which is equally likely, the probability of observing exactly $x$ red balls is \n",
    "$$\n",
    "\\frac{{N_R\\choose x} {N_G\\choose n-x}}{{N\\choose n}}.\n",
    "$$\n",
    "\n",
    "<img src=\"qmark.svg\" width=\"30\" align=\"left\"> **Question:** What is the average number of red balls in the SRS?\n",
    "\n",
    "Soln. \n",
    "\\begin{align*}\n",
    "\\sum_{x=1}^{N_R} x \\frac{{N_R\\choose x} {N_G\\choose n-x}}{{N\\choose n}} \n",
    "&= \\sum_{x=1}^{N_R} N_R \\frac{{N_R - 1\\choose x-1} {N_G\\choose n-x}}{{N\\choose n}} \\\\\n",
    "&= \\frac{N_Rn}{N}\\sum_{x=1}^{N_R}  \\frac{{N_R - 1\\choose x-1} {N_G\\choose n-x}}{\\frac{n}{N}{N\\choose n}} \\\\\n",
    "&= \\frac{N_Rn}{N}\\sum_{x=1}^{N_R}  \\frac{{N_R - 1\\choose x-1} {N_G\\choose n-x}}{{N-1\\choose n - 1}} \\\\\n",
    "&= \\frac{N_Rn}{N}\\underbrace{\\sum_{x=0}^{N_R-1}  \\frac{{N_R - 1\\choose x} {N_G\\choose n-1-x}}{{N-1\\choose n - 1}}}_{=1} \\\\\n",
    "&= \\frac{N_Rn}{N}\n",
    "\\end{align*}\n",
    "\n",
    "Another way of phrasing this is that if we observe $x$ red balls from a SRS of $n$ balls from an urn, on average our estimate $\\frac{x}{n}$ of the proportion $\\frac{N_R}{N}$ will be correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Random Sample\n",
    "\n",
    "In Stratified Sampling, we divide the population into distinct subpopulations called *strata* and obtain random samples from each stratum. If we care about studying each subpopulation on its own or comparing them, of course it makes sense to stratify. But we are only asking questions about the entire population, we might still turn to stratification if:\n",
    "   - It is more feasible. For example, geographic stratification in a large scale household study can organize the data collection effort and allow the surveyor to allocate a fixed amount of resources to studying each region.\n",
    "   - It can lead to more precise estimates.\n",
    "\n",
    "To understand the latter we return to the urn model. Now the balls are divided into $K$ urns, each with $N^{(k)}$ balls, such that $\\sum_{k=1}^KN^{(k)} = N$. Similarly each stratum contains $N_R^{(k)}$ and $N_G^{(k)}$ red and green balls, respectively, so $N^{(k)} = N_R^{(k)} + N_G^{(k)}$. We sample $n^{(k)}$ without replacement from each stratum and $n = \\sum_{k=1}^K n^{(k)}$ balls in total. Suppose we observe $x^{(k)}$ red balls in each urn, and estimate the proportion with the weighted average\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\left(\\frac{N^{(k)}}{N}\\right)\\frac{x^{(k)}}{n^{(k)}}.\n",
    "$$\n",
    "\n",
    "<img src=\"qmark.svg\" width=\"30\" align=\"left\"> **Question:** What's the average value of the proportion?\n",
    "\n",
    "Soln. We know from SRS that the average value of $\\frac{x^{(k)}}{n^{(k)}}$ is $\\frac{N_R^{(k)}}{N^{(k)}}$. Hence the average value of our weighted proportion is \n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\left(\\frac{N^{(k)}}{N}\\right)\\frac{N_R^{(k)}}{N^{(k)}} = \\sum_{k=1}^K \\frac{N_R^{(k)}}{N},\n",
    "$$\n",
    "\n",
    "which simplifies to \n",
    "\n",
    "$$\n",
    "\\frac{N_R}{N}.\n",
    "$$\n",
    "\n",
    "The weighted proportion is right on average as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustered Random Sample\n",
    "\n",
    "In Cluster Sampling, we group the $N$ balls into $C$ equally sized clusters. Now the urn is filled with $C$ packets, each with $\\frac{N}{C}$ balls, and we pick out $\\frac{nC}{N}$ packets to observe a total of $n$ balls. If $x^{(c)}$ denotes the number of red balls in cluster $c$, and we observe a subset of clusters $\\mathcal O \\subset \\{1,\\dots,C\\}$, the proportion\n",
    "\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{c\\in \\mathcal O}x^{c},\n",
    "$$\n",
    "\n",
    "is also right on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"qmark.svg\" width=\"30\" align=\"left\"> **Question:** Which sampling procedure should we prefer for measuring the presence of an attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SRS(n,URN):\n",
    "    flattened_urn = URN.flatten()\n",
    "    return np.mean(np.random.choice(flattened_urn,n,replace=False))\n",
    "\n",
    "def SS(n,URN):\n",
    "    K = URN.shape[0]\n",
    "    return np.mean([np.random.choice(URN[k,:],int(n/K),replace=False) for k in range(K)])\n",
    "\n",
    "def CS(n,URN):\n",
    "    cluster_size, n_clusters = URN.shape\n",
    "    return URN[:, np.random.choice(C, n // cluster_size, replace=False)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 10000\n",
    "K=3\n",
    "pk = [0.25,0.75,0.2]\n",
    "C=2000\n",
    "\n",
    "URN = np.array([np.random.binomial(1,pk[k],size=C) for k in range(K)])\n",
    "p = np.mean(URN) # true proportion of reds in URN\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.hist([SRS(1200,URN)  for _ in range(S)],bins=30,alpha=1., label=\"Simple Random Sample\")\n",
    "plt.hist([SS(1200,URN) for _ in range(S)],bins=30,alpha=0.75, label=\"Stratified Random Sample\")\n",
    "plt.hist([CS(1200,URN) for _ in range(S)],bins=30,alpha=0.75, label=\"Cluster Sample\")\n",
    "plt.plot([p,p],[0,1300],'b--', label=\"Proportion of Red in Urn\")\n",
    "plt.axis([0.35,0.45,0,1300])\n",
    "plt.legend()\n",
    "plt.xlabel(\"Fraction of Red in Sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"qmark.svg\" width=\"30\" align=\"left\"> **Question:** What does this plot mean? What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read these links on when different sampling techniques are useful:\n",
    "\n",
    "- https://www.wikiwand.com/en/Stratified_sampling#/Advantages\n",
    "- https://www.wikiwand.com/en/Cluster_sampling#/Applications_of_cluster_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}