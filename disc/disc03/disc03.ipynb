{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 03: HW2 Recap, Data Cleaning, and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this discussion, we will recap HW2 and go over important EDA concepts to understand when working with data.\n",
    "\n",
    "Specifically, we'll discuss:\n",
    "\n",
    "- Question 3b (zip_counts, groupby)\n",
    "- Question 7a (score_pairs_by_business, groupby using filter https://pandas.pydata.org/pandas-docs/stable/groupby.html#filtration)\n",
    "- Question 8c (num_vio, pd.merge vs. pd.join)\n",
    "\n",
    "Then, we'll recap EDA:\n",
    "\n",
    "- Structure\n",
    "- Granularity\n",
    "- Scope\n",
    "- Temporality\n",
    "- Faithfulness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW2 Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the big takeaways from HW2:\n",
    "\n",
    "1. Data are messy and often really hard to deal with! Eg. zipcodes and locations of businesses.\n",
    "2. Restaurants don't often improve their inspection score after their first inspection.\n",
    "3. It's not obvious how exactly the inspection score is influenced by the violations.\n",
    "\n",
    "See https://github.com/hopelessoptimism/happy-healthy-hungry/blob/master/h3.ipynb for another analysis on the same dataset.\n",
    "\n",
    "In terms of writing pandas code, here are our recommendations:\n",
    "\n",
    "1. Write code very incrementally. As soon as you try to chain together >3 functions in a row, you'll start having a really hard time debugging.\n",
    "1. The docs are not superrr helpful. You should use the links of the pandas docs sidebar instead of the actual API reference.\n",
    "1. There are always 5 different ways to do things in pandas. Start with what we've taught in class, then branch out.\n",
    "1. You'll very rarely have to do something more complicated than some combination of `.apply`, `.groupby`, and `pd.merge` because they're very flexible. (You don't need to learn every pandas function there is.)\n",
    "1. When grouping, select out your columns before calling `.groupby`.\n",
    "1. When joining, use `pd.merge`.\n",
    "1. Avoid mutation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "dsDir = \"data/\"\n",
    "\n",
    "bus = pd.read_csv(os.path.join(dsDir, \"businesses.csv\"), encoding='ISO-8859-1')\n",
    "ins = pd.read_csv(os.path.join(dsDir, \"inspections.csv\"))\n",
    "vio = pd.read_csv(os.path.join(dsDir, \"violations.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3b\n",
    "\n",
    "To explore the zip code values, it makes sense to examine counts, i.e., the number of records  that have the same zip code value. This is essentially answering the question: How many restaurants are in each zip code? \n",
    "\n",
    "Please generate a dataframe with `postal_code` as the index and a column called `count` which denotes the number of restaurants for each zip code.   If the zipcode is missing be sure to replace it with `MISSING` (e.g., by using `fillna`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- Lots of people had trouble with fillna, so explain what that does\n",
    "- Lots of people had trouble using groupby()/value_counts() and getting a DataFrame back, so talk about the `.to_frame()` method.\n",
    "- **We recommend using `.loc[]` to slice out the columns you want to group first, then using `.groupby`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION 1\n",
    "zip_counts = ...\n",
    "\n",
    "# SOLUTION 2\n",
    "zip_counts = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus['zip_code'] = bus['postal_code'].str[:5].str.replace(\"94602\", \"94102\")\n",
    "ins2016 = ins[pd.to_datetime(ins['date'], format='%Y%m%d').dt.year == 2016]\n",
    "vio['new_date'] = pd.to_datetime(vio['date'], format='%Y%m%d')\n",
    "vio2016 = vio[vio['new_date'].dt.year == 2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Question 7a\n",
    "\n",
    "What's the relationship between the first and second scores for the businesses with 2 inspections in a year? Do they typically improve?\n",
    "\n",
    "First, make a dataframe called, `scores_pairs_by_business`, indexed by business_id (containing only business with exactly 2 inspections in 2016).  This dataframe contains the field `score_pair` consisting of the score pairs ordered chronologically  `[first_score, second_score]`. \n",
    "\n",
    "Plot these scores. That is, make a scatter plot to display these pairs of scores. Include on the plot a reference line with slope 1. \n",
    "\n",
    "You may find the functions `sort_values`, `groupby`, `filter` and `agg` helpful, though not all necessary. \n",
    "\n",
    "The first few rows resulting table should look something like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>score_pair</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>business_id</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>24</th>\n",
    "      <td>[96, 98]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>45</th>\n",
    "      <td>[78, 84]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>66</th>\n",
    "      <td>[98, 100]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>67</th>\n",
    "      <td>[87, 94]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>76</th>\n",
    "      <td>[100, 98]</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- Turns out that `.filter` for `groupby` is different from `.filter` for DataFrames. Make sure to point this out.\n",
    "- To groupby and then convert to a list, use `.agg` with a user-defined function. For more advanced users, use `.apply` on the groupby: https://stackoverflow.com/a/22221675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION CELL\n",
    "scores_pairs_by_business = ...\n",
    "scores_pairs_by_business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8c\n",
    "Derive a variable, `num_vio`, that contains the number of violations in a restaurant inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- Again, there was confusion about how to use groupby with size to get a dataframe, so you should talk about how  reset_index works for Series.\n",
    "- There was lots of confusion about how `pd.merge` works. You should discuss that in more detail and the difference between `pd.join` and `pd.merge`: https://stackoverflow.com/a/37891437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vios = ...\n",
    "ins2016['num_vio'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"qmark.svg\" width=\"20px\" style=\"display:inline\"> Discussion question (10 mins): In the Berkeley Police Calls dataset that Joey discussed in lecture:\n",
    "\n",
    "1. What is the structure of the dataset?\n",
    "2. What is the granularity of the dataset?\n",
    "3. What is the scope of the dataset?\n",
    "4. What is the temporality of the dataset?\n",
    "5. What is the faithfulness of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"qmark.svg\" width=\"20px\" style=\"display:inline\"> Discussion question (10 mins): Go over vitamin questions, if people had any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If time allows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a dataset with your partner! Here are some suggestions of places to look:\n",
    "\n",
    "- Berkeley Open Data: https://data.cityofberkeley.info/browse?limitTo=datasets&utf8=&page=1 \n",
    "- Transparent California: http://transparentcalifornia.com/\n",
    "- Big list of Public Datasets: https://github.com/caesar0301/awesome-public-datasets\n",
    "\n",
    "<img src=\"qmark.svg\" width=\"20px\" style=\"display:inline\"> Discussion question (10 mins): After picking your dataset, downlaod it, load it in, and answer the following questions with your partner:\n",
    "\n",
    "1. What is the structure of the dataset?\n",
    "2. What is the granularity of the dataset?\n",
    "3. What is the scope of the dataset?\n",
    "4. What is the temporality of the dataset?\n",
    "5. What is the faithfulness of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"qmark.svg\" width=\"20px\" style=\"display:inline\"> Discussion question (10 mins): Use `seaborn` to create a visualization showing something you didn't know before about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}