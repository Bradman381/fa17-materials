{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Trump, Twitter, and Text\n",
    "\n",
    "Welcome to the first project of DS100! In this project, we will work with the Twitter API in order to analyze Donald Trump's tweets.\n",
    "\n",
    "**The project checkpoint is due 11:59pm Tuesday, Sept. 26.** The checkpoint is graded on *completeness*, not correctness. You must complete Questions 1-4 in order to get full credit for the checkpoint.\n",
    "\n",
    "**The entire project is due 11:59pm Tuesday, Oct 3.**\n",
    "\n",
    "*Fair warning:* This project involves significantly more challenging pandas operations than the previous homeworks. We strongly suggest you start early.\n",
    "\n",
    "**Grading:**\n",
    "\n",
    "The checkpoint is worth **10%** of the overall project grade and is graded on completeness.\n",
    "\n",
    "However, the final submission of the project will be graded on **correctness**.\n",
    "\n",
    "**Fun:**\n",
    "\n",
    "We intended this project to be fun! You will analyze actual data from the Twitter API â€” no precooked dataset this time around. You will also draw conclusions about the current (and often controversial) US President's tweet behavior. If you find yourself getting frustrated or stuck on one problem for too long, we suggest coming into office hours and working with friends in the class.\n",
    "\n",
    "With that in mind, let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "import re\n",
    "\n",
    "from IPython.display import display, Latex, Markdown\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('proj1.ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into OkPy. You may have to change this to ok.auth(force=True) if you run into\n",
    "# an OAuthError\n",
    "ok.auth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "# Getting the dataset\n",
    "\n",
    "---\n",
    "\n",
    "Since we'll be looking at Twitter data, we need to download the data from Twitter!\n",
    "\n",
    "Twitter provides an API for downloading tweet data in large batches.  The `tweepy` package makes it fairly easy to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "Install `tweepy`, if you don't already have it.  (Be sure to activate your Conda environment for the class first.  Then run `pip install tweepy`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Make sure you are in your ds100 conda environment.\n",
    "## Uncomment the following line to install tweepy\n",
    "# !pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following should run\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are instructions on using `tweepy` [here](http://tweepy.readthedocs.io/en/v3.5.0/getting_started.html), but we will give you example code.\n",
    "\n",
    "Twitter requires you to have authentication keys to access their API.  To get your keys, you'll have to sign up as a Twitter developer.  The next question will walk you through this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/>\n",
    "\n",
    "## Question 1\n",
    "\n",
    "Follow the instructions below to get your Twitter API keys.  Read the instructions completely before starting.\n",
    "\n",
    "1. [Create a Twitter account](https://twitter.com).  You can use an existing account if you have one.\n",
    "2. Under account settings, add your phone number to the account.\n",
    "3. [Create a Twitter developer account](https://dev.twitter.com/resources/signup).  Attach it to your Twitter account.\n",
    "4. Once you're logged into your developer account, [create an application for this assignment](https://apps.twitter.com/app/new).  You can call it whatever you want, and you can write any URL when it asks for a web site.\n",
    "5. On the page for that application, find your Consumer Key and Consumer Secret.\n",
    "6. On the same page, create an Access Token.  Record the resulting Access Token and Access Token Secret.\n",
    "7. Edit the file [keys.json](keys.json) and replace the placeholders with your keys.  Don't turn in that file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## WARNING (Please Read) !!!!\n",
    "\n",
    "\n",
    "### Protect your Twitter Keys\n",
    "<span style=\"color:red\">\n",
    "If someone has your authentication keys, they can access your Twitter account and post as you!  So don't give them to anyone, and **don't write them down in this notebook**. \n",
    "</span>\n",
    "The usual way to store sensitive information like this is to put it in a separate file and read it programmatically.  That way, you can share the rest of your code without sharing your keys.  That's why we're asking you to put your keys in `keys.json` for this assignment.\n",
    "\n",
    "\n",
    "### Avoid making too many API calls.\n",
    "\n",
    "<span style=\"color:red\">\n",
    "Twitter limits developers to a certain rate of requests for data.  If you make too many requests in a short period of time, you'll have to wait awhile (around 15 minutes) before you can make more.  </span> \n",
    "So carefully follow the code examples you see and don't rerun cells without thinking.  Instead, always save the data you've collected to a file.  We've provided templates to help you do that.\n",
    "\n",
    "\n",
    "### Be careful about which functions you call!\n",
    "\n",
    "<span style=\"color:red\">\n",
    "This API can retweet tweets, follow and unfollow people, and modify your twitter settings.  Be careful which functions you invoke! </span> One of your instructors accidentally re-tweeted some tweets because that instructor typed `retweet` instead of `retweet_count`. \n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "key_file = 'keys.json'\n",
    "# Loading your keys from keys.json (which you should have filled\n",
    "# in in question 1):\n",
    "with open(key_file) as f:\n",
    "    keys = json.load(f)\n",
    "# if you print or view the contents of keys be sure to delete the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell tests the Twitter authentication. It should run without errors or warnings and display your Twitter username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import TweepError\n",
    "import logging\n",
    "\n",
    "try:\n",
    "    auth = tweepy.OAuthHandler(keys[\"consumer_key\"], keys[\"consumer_secret\"])\n",
    "    auth.set_access_token(keys[\"access_token\"], keys[\"access_token_secret\"])\n",
    "    api = tweepy.API(auth)\n",
    "    print(\"Your username is:\", api.auth.get_username())\n",
    "except TweepError as e:\n",
    "    logging.warning(\"There was a Tweepy error. Double check your API keys and try again.\")\n",
    "    logging.warning(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "## Question 2\n",
    "\n",
    "In the example below, we have loaded some tweets by @BerkeleyData.  Run it and read the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ds_tweets_save_path = \"BerkeleyData_recent_tweets.pkl\"\n",
    "# Guarding against attempts to download the data multiple\n",
    "# times:\n",
    "if not Path(ds_tweets_save_path).is_file():\n",
    "    # Obtaining twitter keys\n",
    "    import json\n",
    "    key_file = 'keys.json'\n",
    "    # Loading your keys from keys.json (which you should have filled\n",
    "    # in in question 1):\n",
    "    with open(key_file) as f:\n",
    "        keys = json.load(f)\n",
    "    \n",
    "    # Authenticating:\n",
    "    import tweepy\n",
    "    auth = tweepy.OAuthHandler(keys[\"consumer_key\"], keys[\"consumer_secret\"])\n",
    "    auth.set_access_token(keys[\"access_token\"], keys[\"access_token_secret\"])\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # Getting as many recent tweets by @BerkeleyData as Twitter will let us have:\n",
    "    example_tweets = list(tweepy.Cursor(api.user_timeline, id=\"BerkeleyData\").items())\n",
    "\n",
    "    # Saving the tweets to a file as \"pickled\" objects:\n",
    "    with open(ds_tweets_save_path, \"wb\") as f:\n",
    "        import pickle\n",
    "        pickle.dump(example_tweets, f)\n",
    "\n",
    "# Re-loading the results:\n",
    "with open(ds_tweets_save_path, \"rb\") as f:\n",
    "    import pickle\n",
    "    example_tweets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming everything ran correctly you should be able to look at the first tweet by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Looking at one tweet object, which has type Status: \n",
    "from pprint import pprint # ...to get a more easily-readable view.\n",
    "pprint(example_tweets[0]._json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What you need to do. \n",
    "\n",
    "Re-factor the above code fragment into reusable snippets below.  You should not need to make major modifications; this is mostly an exercise in understanding the above code block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def load_keys(path):\n",
    "    \"\"\"Loads your Twitter authentication keys from a file on disk.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The path to your key file.  The file should\n",
    "          be in JSON format and look like this (but filled in):\n",
    "            {\n",
    "                \"consumer_key\": \"<your Consumer Key here>\",\n",
    "                \"consumer_secret\":  \"<your Consumer Secret here>\",\n",
    "                \"access_token\": \"<your Access Token here>\",\n",
    "                \"access_token_secret\": \"<your Access Token Secret here>\"\n",
    "            }\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary mapping key names (like \"consumer_key\") to\n",
    "          key values.\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def download_recent_tweets_by_user(user_account_name, keys):\n",
    "    \"\"\"Downloads tweets by one Twitter user.\n",
    "\n",
    "    Args:\n",
    "        user_account_name (str): The name of the Twitter account\n",
    "          whose tweets will be downloaded.\n",
    "        keys (dict): A Python dictionary with Twitter authentication\n",
    "          keys (strings), like this (but filled in):\n",
    "            {\n",
    "                \"consumer_key\": \"<your Consumer Key here>\",\n",
    "                \"consumer_secret\":  \"<your Consumer Secret here>\",\n",
    "                \"access_token\": \"<your Access Token here>\",\n",
    "                \"access_token_secret\": \"<your Access Token Secret here>\"\n",
    "            }\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Status objects, each representing one tweet.\"\"\"\n",
    "    import tweepy\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def save_tweets(tweets, path):\n",
    "    \"\"\"Saves a list of tweets to a file in the local filesystem.\n",
    "    \n",
    "    This function makes no guarantee about the format of the saved\n",
    "    tweets, **except** that calling load_tweets(path) after\n",
    "    save_tweets(tweets, path) will produce the same list of tweets\n",
    "    and that only the file at the given path is used to store the\n",
    "    tweets.  (That means you can implement this function however\n",
    "    you want, as long as saving and loading works!)\n",
    "\n",
    "    Args:\n",
    "        tweets (list): A list of tweet objects (of type Status) to\n",
    "          be saved.\n",
    "        path (str): The place where the tweets will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def load_tweets(path):\n",
    "    \"\"\"Loads tweets that have previously been saved.\n",
    "    \n",
    "    Calling load_tweets(path) after save_tweets(tweets, path)\n",
    "    will produce the same list of tweets.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The place where the tweets were be saved.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Status objects, each representing one tweet.\"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def get_tweets_with_cache(user_account_name, keys_path):\n",
    "    \"\"\"Get recent tweets from one user, loading from a disk cache if available.\n",
    "    \n",
    "    The first time you call this function, it will download tweets by\n",
    "    a user.  Subsequent calls will not re-download the tweets; instead\n",
    "    they'll load the tweets from a save file in your local filesystem.\n",
    "    All this is done using the functions you defined in the previous cell.\n",
    "    This has benefits and drawbacks that often appear when you cache data:\n",
    "    \n",
    "    +: Using this function will prevent extraneous usage of the Twitter API.\n",
    "    +: You will get your data much faster after the first time it's called.\n",
    "    -: If you really want to re-download the tweets (say, to get newer ones,\n",
    "       or because you screwed up something in the previous cell and your\n",
    "       tweets aren't what you wanted), you'll have to find the save file\n",
    "       (which will look like <something>_recent_tweets.pkl) and delete it.\n",
    "    \n",
    "    Args:\n",
    "        user_account_name (str): The Twitter handle of a user, without the @.\n",
    "        keys_path (str): The path to a JSON keys file in your filesystem.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything was implemented correctly you should be able to obtain roughly the last 3000 tweets by the `realdonaldtrump`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you are done, run this cell to load @realdonaldtrump's tweets.\n",
    "# Note the function get_tweets_with_cache.  You may find it useful\n",
    "# later.\n",
    "trump_tweets = get_tweets_with_cache(\"realdonaldtrump\", key_file)\n",
    "print(\"Number of tweets downloaded:\", len(trump_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/>\n",
    "\n",
    "## Question 3\n",
    "\n",
    "In this question you will extract important fields from the tweet objects and convert them into a Pandas dataframe for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each trump tweet is stored in a `tweepy.models.Status` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trump_tweets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list all the members of this object by looking at the private `__dict__` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(trump_tweets[0].__dict__.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we can extract a field simply by reading its value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweets[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you need to do\n",
    "\n",
    "Construct a DataFrame called `trump`. The index of the dataframe should be the ID of each tweet (looks something like `907698529606541312`). It should have these columns:\n",
    "\n",
    "- `time`: The time the tweet was created.\n",
    "- `source`: The source device of the tweet.\n",
    "- `text`: The text of the tweet.\n",
    "- `retweet_count`: The retweet count of the tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q03"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q03')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two important dates that we'll use in our analysis. `ELEC_DATE` is the date when Trump won the 2016 Presidential election, and `INAUG_DATE` is the date that Trump was sworn into office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "ELEC_DATE = datetime(2016, 11, 8)\n",
    "INAUG_DATE = datetime(2017, 1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the first and last rows of your tweet data.\n",
    "\n",
    "You'll notice that the data contains tweets from before the election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump.iloc[[0, -1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Tweet Source Analysis\n",
    "\n",
    "In the following questions, we are going to find out the charateristics of Trump tweets and the devices used for the tweets.\n",
    "\n",
    "---\n",
    "<br/><br/>\n",
    "\n",
    "## Question 4a\n",
    "\n",
    "Find out the number of unique sources of the Trump tweets. Save the result in `num_sources`. \n",
    "\n",
    "Then, make a bar plot of the counts of different sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "num_sources = ...\n",
    "\n",
    "# make a bar plot here\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q04a"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q04a')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, Trump tweets are mostly from iPhone or Android. Is there a difference between his Tweet behavior between the two devices?\n",
    "\n",
    "We will attempt to answer this question in our subsequent analysis.\n",
    "\n",
    "First, we'll take a look at whether Trump's tweets from an Android come at different times than his tweets from an iPhone. Note that Twitter gives us his tweets in the [UTC timezone](https://www.wikiwand.com/en/List_of_UTC_time_offsets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trump_tweets[0]._json['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert the tweet times to US Eastern Time, the timezone of New York and Washington D.C., since those are the places we would expect the most tweet activity from Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump['est_time'] = pd.Index(trump['time']).tz_localize(\"UTC\").tz_convert(\"US/Eastern\")\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/>\n",
    "\n",
    "## Question 4b\n",
    "\n",
    "Use this data to make a line plot with two curves:\n",
    "\n",
    "1. The number of iPhone tweets vs. hour of the day, normalized over the hours of the day. For example, if there were 10 tweets at 1pm and 20 tweets at 2pm, the line plot should be 0, then 0.33 at 1pm, 0.66 at 2pm, then back to 0.\n",
    "2. The same curve for Android tweets.\n",
    "\n",
    "Put the two curves in the same plot. You should get a plot that looks like:\n",
    "\n",
    "![](device_hour.png)\n",
    "\n",
    "Hint: use `value_counts` with `normalization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "### make your plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<br></br>\n",
    "\n",
    "## Question 4c\n",
    "What can you find out in the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "q4c_answer = r\"\"\"\n",
    "\n",
    "Put your answer here, replacing this text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(q4c_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<br></br>\n",
    "\n",
    "Let's now look at his tweet device usage over the entire time period we have in the dataset.\n",
    "\n",
    "Take a look at the code below and the plot it generates.\n",
    "\n",
    "You should be answer the following questions about this code. You don't have to write the answers down anywhere, but you'll need to make variations of this plot in later questions so understanding this code will help you greatly.\n",
    "\n",
    "1. What does `set_index` do here?\n",
    "1. What does `resample` do? What does the `'D'` argument do in `resample`?\n",
    "1. What does `unstack` do? What does the `level=0` argument do in unstack?\n",
    "1. Why does one call to `plot()` generate 7 lines?\n",
    "\n",
    "Feel free to copy this cell, play around with the code to see the intermediate result, then delete your cell after you're done.\n",
    "\n",
    "(**Also, all the questions in this project can be answered using this style of method chaining.** If you write `for` loops in this project, know that there is a better way.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trump.loc[:, ['est_time', 'source']]\n",
    " .set_index('est_time')\n",
    " .groupby('source')\n",
    " .resample('D')\n",
    " .size()\n",
    " .unstack(level=0)\n",
    " .plot()\n",
    ")\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4d\n",
    "\n",
    "One problem with the plot above is that it plots too many points to see overall trends in the device usage.\n",
    "\n",
    "Recreate the plot above, grouping by each month instead of each day. You may want to use the `figsize` argument to `plot` to make your plot larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "### make your plot here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the plot, Trump's tweets come from many different sources. It turns out that many of his tweets were not from Trump himself but from his staff. [Take a look at this Verge article.](https://www.theverge.com/2017/3/29/15103504/donald-trump-iphone-using-switched-android)\n",
    "\n",
    "Does the data support the information in the article? What else do you find out about changes in Trump's tweets sources from the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "q4d_answer = r\"\"\"\n",
    "\n",
    "Put your answer here, replacing this text.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(q4d_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some ways we can distinguish between tweets that came from Trump and tweets from his staff? Before, it was as easy as checked which device the tweet came from. Now, we have to rely on more sophisticated methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Checkpoint Reached\n",
    "\n",
    "Congrats, you just reached the Project 1 checkpoint!\n",
    "\n",
    "Now, run the cell below to submit your assignment to OkPy. The autograder should email you shortly with your autograded score. The autograder will only run once every 30 minutes.\n",
    "\n",
    "Note that you'll probably get 0 points on Questions 5-8. Since you haven't gotten there yet, don't worry about missing those points.\n",
    "\n",
    "**Note that the checkpoint is graded on completeness. This means that we'll check whether you attempted to solve each question, not whether you've gotten them right. When you submit the final submission of the project, you can go back and revise your answers to Questions 1-4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br></br>\n",
    "\n",
    "## Question 5: Sentiment Analysis\n",
    "\n",
    "It turns out that we can use the words in Trump's tweets to calculate a measure of the sentiment of the tweet. For example, the sentence \"I love America!\" has positive sentiment, whereas the sentence \"I hate taxes!\" has a negative sentiment. In addition, some words have stronger positive / negative sentiment than others: \"I love America.\" is more positive than \"I like America.\"\n",
    "\n",
    "We will use the [VADER (Valence Aware Dictionary and sEntiment Reasoner)](https://github.com/cjhutto/vaderSentiment) lexicon to analyze the sentiment of Trump's tweets. VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media which is great for our usage.\n",
    "\n",
    "The VADER lexicon gives the sentiment of individual words. Run the following cell to show the first few rows of the lexicon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head vader_lexicon.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/>\n",
    "\n",
    "## Question 5a\n",
    "\n",
    "As you can see, the lexicon contains emojis too! The first column of the lexicon is the *token*, or the word itself. The second column is the *polarity* of the word, or how positive / negative it is.\n",
    "\n",
    "(How did they decide the polarities of these words? What are the other two columns in the lexicon? See the link above.)\n",
    "\n",
    " Read in the lexicon into a DataFrame called `sent`. The index of the DF should be the tokens in the lexicon. `sent` should have one column: `polarity`: The polarity of each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "sent = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q05a"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q05a')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/>\n",
    "\n",
    "## Question 5b\n",
    "\n",
    "Now, let's use this lexicon to calculate the overall sentiment for each of Trump's tweets. Here's the basic idea:\n",
    "\n",
    "1. For each tweet, find the sentiment of each word.\n",
    "2. Calculate the sentiment of each tweet by taking the sum of the sentiments of its words.\n",
    "\n",
    "First, let's lowercase the text in the tweets since the lexicon is also lowercase. Set the `text` column of the `trump` DF to be the lowercased text of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q05b"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q05b')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/>\n",
    "\n",
    "## Question 5c\n",
    "\n",
    "Now, let's get rid of punctuation since it'll cause us to fail to match words. Create a new column called `no_punc` in the `trump` DF to be the lowercased text of each tweet with all punctuation replaced by a single space. We consider punctuation characters to be any character that isn't a Unicode word character or a whitespace character. You may want to consult the Python documentation on regexes for this problem.\n",
    "\n",
    "(Why don't we simply remove punctuation instead of replacing with a space? See if you can figure this out by looking at the tweet data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Save your regex in punct_re\n",
    "punct_re = r''\n",
    "trump['no_punc'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q05c"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q05c')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/> <br/>\n",
    "\n",
    "## Question 5d:\n",
    "\n",
    "\n",
    "Now, let's convert the tweets into what's called a *tidy format* to make the sentiments easier to calculate. Use the `no_punc` column of `trump` to create a table called `tidy_format`. The index of the table should be the IDs of the tweets, repeated once for every word in the tweet. It has two columns:\n",
    "\n",
    "1. `num`: The location of the word in the tweet. For example, if the tweet was \"i love america\", then the location of the word \"i\" is 0, \"love\" is 1, and \"america\" is 2.\n",
    "2. `word`: The individual words of each tweet.\n",
    "\n",
    "The first few rows of our `tidy_format` table look like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>num</th>\n",
    "      <th>word</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>907698529606541312</th>\n",
    "      <td>0</td>\n",
    "      <td>it</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>907698529606541312</th>\n",
    "      <td>1</td>\n",
    "      <td>was</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>907698529606541312</th>\n",
    "      <td>2</td>\n",
    "      <td>a</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>907698529606541312</th>\n",
    "      <td>3</td>\n",
    "      <td>great</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>907698529606541312</th>\n",
    "      <td>4</td>\n",
    "      <td>honor</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "**Note that you'll get different results depending on when you pulled in the tweets.** However, you can double check that your tweet with ID `907698529606541312` has the same rows as ours. Our tests don't check whether your table looks exactly like ours.\n",
    "\n",
    "This will require some rather advanced Pandas hacking, but our solution uses a chain of 5 methods on the `trump` DF.\n",
    "\n",
    "* **Hint 1:** Try looking at the `expand` argument to pandas' `str.split`.\n",
    "\n",
    "* **Hint 2:** Try looking at the `stack()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "tidy_format = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q05d"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q05d')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/> <br/>\n",
    "\n",
    "\n",
    "## Question 5e:\n",
    "\n",
    "Now that we have this table in the tidy format, it becomes much easier to find the sentiment of each tweet: we can join the table with the lexicon table. Calculate a table called `polarities`. Its index should be the IDs of the tweets (one row per ID). It should have one column called `polarity` containing the summed sentiment polarity of each tweet.\n",
    "\n",
    "Here are the first couple rows of our table. Again, you may have different tweet IDs depending on when you downloaded the tweets, but make sure the format looks the same.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>polarity</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>index</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>755486029742641152</th>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>755502053003190273</th>\n",
    "      <td>0.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>755525857456844800</th>\n",
    "      <td>2.2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>755551039244341253</th>\n",
    "      <td>6.7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>755708398537154560</th>\n",
    "      <td>7.6</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "polarities = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q05e"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q05e')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/> <br/>\n",
    "\n",
    "\n",
    "## Question 5f:\n",
    "\n",
    "Finally, use the `polarities` and `trump` tables to create a new table called `senti` that is the `trump` table with an extra column called `polarity` containing the sentiment polarity of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "senti = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q05f"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q05f')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a measure of the sentiment of each of his tweets! Note that this calculation is rather basic; you can read over the VADER readme to understand a more robust sentiment analysis.\n",
    "\n",
    "Now, run the cells below to see the most positive and most negative tweets from Trump in your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most negative tweets:')\n",
    "for t in senti.sort_values('polarity').head()['text']:\n",
    "    print('  ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Most positive tweets:')\n",
    "for t in senti.sort_values('polarity', ascending=False).head()['text']:\n",
    "    print('  ', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br></br>\n",
    "\n",
    "## Question 5g\n",
    "\n",
    "Use seaborn to create a `distplot` of the sentiments. What do you notice? (You don't have to write this down in the notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### make your plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br></br>\n",
    "\n",
    "## Question 5h\n",
    "Create a line plot of the sentiment of Trump's tweets over time. Plot the mean sentiment of each month of his tweets over time. Then, plot vertical lines corresponding to his election and inauguration dates. Your final plot should look like:\n",
    "\n",
    "![](senti_time.png)\n",
    "\n",
    "Then, describe what you notice and save your result in the variable `senti_time_answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "# Create your plot here...\n",
    "\n",
    "...\n",
    "\n",
    "# ...then write your takeaways here.\n",
    "senti_time_answer = '''\n",
    "\n",
    "Write your answer here, replacing this text.\n",
    "\n",
    "'''\n",
    "display(Markdown(senti_time_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Hashtags\n",
    "\n",
    "Let's return now to the problem of determining which tweets were from Trump and which were from his aides. As a reminder, most analysts agree that tweets that came from an Android device were likely from Trump himself, not one of his aides ([example](http://didtrumptweetit.com/machine-learning-tweet-prediction/)).\n",
    "\n",
    "In addition, browsing his Twitter shows that some tweets that sound more \"official\" often have a hashtag, link, or a picture:\n",
    "\n",
    "![](aide.png)\n",
    "\n",
    "Whereas tweets that sound like Trump himself usually don't have a hashtag, link, or picture:\n",
    "\n",
    "![](trump.png)\n",
    "\n",
    "So, we can hypothesize that if a tweet has a hashtag, link, or picture it came from one of Trump's aides, not Trump himself. Let's see if this idea is backed up by the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br></br>\n",
    "\n",
    "## Question 6a\n",
    "\n",
    "Create a DF called `hash_or_link` that contains only the rows from the `senti` table where the tweet isn't a retweet and contains a hashtag, link, or picture. We say that:\n",
    "\n",
    "- A tweet is a retweet if it has the string 'rt' anywhere in the tweet if it is preceeded and followed by a non-word character (the start and end of the string count as non-word characters).\n",
    "- A tweet has a hashtag if it has the character '#' anywhere in the tweet followed by a letter.\n",
    "- A tweet contains a link or a picture if it has the word `http` anywhere in the tweet\n",
    "\n",
    "(You can check out Trump's Twitter for why these criteria are true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# You must save your regex for retweets in this variable\n",
    "rt_re = r''\n",
    "# You must save your regex for hashtags, links, or pictures in this variable\n",
    "hash_re = r''\n",
    "hash_or_link = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q06a"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q06a')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<br></br>\n",
    "\n",
    "## Question 6b\n",
    "\n",
    "Create a line plot of the number of tweets containing a hashtag, link, or picture from each tweet device.\n",
    "\n",
    "If a device doesn't have at least 20 tweets in a particular year, don't include the tweets from that device for that year. (Eg. if there are 100 tweets from Twitter Ads in 2016 but only 10 in 2017, plot the counts for Twitter Ads in 2016 but not 2017.)\n",
    "\n",
    "Aggregate the counts for each week period. Your final plot should look like:\n",
    "\n",
    "![](hashtag_by_device.png)\n",
    "\n",
    "*Hint:* If you can get a table in the following format, you can just call `.plot()` on it to generate the plot.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>source</th>\n",
    "      <th>Media Studio</th>\n",
    "      <th>Twitter Ads</th>\n",
    "      <th>Twitter Web Client</th>\n",
    "      <th>Twitter for Android</th>\n",
    "      <th>Twitter for iPhone</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>time</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>2016-07-24</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>4.0</td>\n",
    "      <td>10.0</td>\n",
    "      <td>14.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2016-08-07</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>5.0</td>\n",
    "      <td>15.0</td>\n",
    "      <td>91.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2016-08-21</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>9.0</td>\n",
    "      <td>10.0</td>\n",
    "      <td>44.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2016-09-04</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>0.0</td>\n",
    "      <td>20.0</td>\n",
    "      <td>51.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2016-09-18</th>\n",
    "      <td>NaN</td>\n",
    "      <td>NaN</td>\n",
    "      <td>1.0</td>\n",
    "      <td>12.0</td>\n",
    "      <td>59.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "What conclusions can you draw from this plot? Does this plot allow us to say whether a tweet containing a hashtag/link/picture likely came from Trump himself? Write your takeaways in `hashtag_answer` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "# Create your plot here...\n",
    "\n",
    "...\n",
    "\n",
    "# ...then write your takeaways here.\n",
    "hashtag_answer = '''\n",
    "\n",
    "Write your answer here, replacing this text.\n",
    "\n",
    "'''\n",
    "display(Markdown(hashtag_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<br></br>\n",
    "\n",
    "## Question 6c \n",
    "\n",
    "Now, let's see whether there's a difference in sentiment for tweets with hashtags and those without.\n",
    "\n",
    "Create a line plot of the sentiment of Trump's non-retweet tweets over time, taking the mean sentiment for every month. Plot one line for tweets with hashtags and one for tweets without. Then, draw two vertical lines for the election date and inauguration date. Draw a horizontal line for y=0. Your plot should look like:\n",
    "\n",
    "![](hash_senti.png)\n",
    "\n",
    "What do you notice about the plot? What conclusions can you draw? Write your answers in `hash_senti_answer`.\n",
    "\n",
    "Hint 1: You'll want to start use your `senti` table, not your `hash_or_link` table. Try adding a column to `senti` containing True if the tweet has a hashtag/link/picture.\n",
    "\n",
    "Hint 2: You shouldn't use your `no_punc` column. Think about why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "# Create your plot here...\n",
    "\n",
    "...\n",
    "\n",
    "# ...then write your takeaways here.\n",
    "hash_senti_answer = '''\n",
    "\n",
    "Write your answer here, replacing this text.\n",
    "\n",
    "'''\n",
    "display(Markdown(hash_senti_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Question 7: Engagement\n",
    "\n",
    "---\n",
    "<br></br>\n",
    "## Question 7a\n",
    "\n",
    "Which of Trump's tweets had the most retweets? Were there certain words that often led to more retweets?\n",
    "\n",
    "We can find this out by using our `tidy_format` DataFrame. For each word in the `tidy_format` DF, find out the number of retweets that its tweet got. Filter out words that didn't appear in at least 25 tweets, find out the median number of retweets each word got, and save the top 20 most retweeted words into a DataFrame called `top_20`. Your `top_20` table should have this format:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>retweet_count</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>word</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>fake</th>\n",
    "      <td>22963.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>news</th>\n",
    "      <td>20463.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>ds100</th>\n",
    "      <td>20432.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>great</th>\n",
    "      <td>20159.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>class</th>\n",
    "      <td>20121.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "top_20 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q07a"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q07a')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a bar chart of your results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20['retweet_count'].sort_values().plot.barh(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br></br>\n",
    "\n",
    "## Question 7b\n",
    "\n",
    "The phrase \"fake news\" is apparently really popular! We can conclude that Trump's tweets containing \"fake\" and/or \"news\" result in the most retweets relative to words his other tweets. Or can we?\n",
    "\n",
    "Consider each of the statements about possible confounding factors below. State whether each statement is true or false and explain. If the statement is true, state whether the confounding factor could have made \"fake\" and/or \"news\" higher on our list than they should be.\n",
    "\n",
    "1. We didn't restrict our word list to nouns, so we have unhelpful words like \"let\" and \"any\" in our result.\n",
    "1. We didn't remove hashtags in our text, so we have duplicate words (eg. #great and great).\n",
    "1. We didn't account for the fact that Trump's follower count has increased over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "engagement_answer = '''\n",
    "\n",
    "1. Write your answer here, replacing this text.\n",
    "1. Write your answer here, replacing this text.\n",
    "1. Write your answer here, replacing this text.\n",
    "\n",
    "'''\n",
    "display(Markdown(engagement_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 8: Fake News\n",
    "\n",
    "---\n",
    "<br></br>\n",
    "## Question 8a \n",
    "\n",
    "Let's investigate the term \"fake news\" a bit more. Create a table called `fake_counts` that has two columns:\n",
    "\n",
    "1. `fake_news`: The number of tweets containing the term \"fake news\".\n",
    "1. `total`: The total number of tweets for the time period.\n",
    "\n",
    "The index of the table should be datetimes for each two-week period in the data.\n",
    "\n",
    "The resulting table should look like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>fake_news</th>\n",
    "      <th>total</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>time</th>\n",
    "      <th></th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>2016-07-31</th>\n",
    "      <td>0</td>\n",
    "      <td>79</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2016-08-14</th>\n",
    "      <td>0</td>\n",
    "      <td>143</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2016-08-28</th>\n",
    "      <td>0</td>\n",
    "      <td>118</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2016-09-11</th>\n",
    "      <td>0</td>\n",
    "      <td>121</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2016-09-25</th>\n",
    "      <td>0</td>\n",
    "      <td>111</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "fake_counts = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q08a"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q08a')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "<br></br>\n",
    "\n",
    "## Question 8b\n",
    "\n",
    "Now, create a line plot showing the proportion of tweets containing the term \"fake news\" over time. Then, draw two vertical lines corresponding to the election and inauguration dates.\n",
    "\n",
    "What do you notice? Write your conclusions in `fake_news_answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "# Create your plot here...\n",
    "\n",
    "...\n",
    "\n",
    "# ...then write your takeaways here.\n",
    "fake_news_answer = '''\n",
    "\n",
    "Write your answer here, replacing this text.\n",
    "\n",
    "'''\n",
    "display(Markdown(fake_news_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Congrats, you just finished Project 1!\n",
    "\n",
    "Run the cell below to run all the OkPy tests at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"ok_tests\") if q.startswith('q')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to submit your assignment to OkPy. The autograder should email you shortly with your autograded score. The autograder will only run once every 30 minutes.\n",
    "\n",
    "**If you're failing tests on the autograder but pass them locally**, you should simulate the autograder by doing the following:\n",
    "\n",
    "1. In the top menu, click Kernel -> Restart and Run all.\n",
    "2. Run the cell above to run each OkPy test.\n",
    "\n",
    "**You must make sure that you pass all the tests when running steps 1 and 2 in order.** If you are still failing autograder tests, you should double check your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}