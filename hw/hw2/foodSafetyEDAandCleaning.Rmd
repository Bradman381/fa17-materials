---
title: "FoodSafetyHW"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Food Safety

Three files 

Read them. 

*Give them code to read one of them in and have them figure out the other file names and read in?

```{r}
sfDir = "~/DS100/sp17-course-development/food_safety/data/"

bus = read.csv(paste(sfDir, "san_francisco/businesses.csv", sep = ""), 
                  encoding='ISO-8859-1')

ins = read.csv(paste(sfDir, "san_francisco/inspections.csv", sep = ""))

vio = read.csv(paste(sfDir, "san_francisco/violations.csv", sep = ""))
```

## Examining the Business data 

What are the variables in this data frame?

```{r}
names(bus)
```



What is the granularity? Is there one record per bus ID?

Consider checking the number of rows against the number of unique business IDs. Are they the same?

```{r}
nrow(bus)
length(unique(bus$business_id))
```


## Zip codes

What kind of variable is postal code?

*Text Answer

Although it is a number it is not quantitative.
It doesn't make sense to measure differences or scale postal code

How many restaraunts are in each zip code?

```{r}
table(bus$postal_code)
```



We see that there are many blanks, and some bad data where the
postal code got screwed up, e.g. there are 3 Ca and 3 CA values
Also there are some extended postal codes.

Let's clean up the extended ones by dropping the digits beyond the first 5.
Remember to keep the original variable. Call the new variable zip

```{r}
bus$zip = as.character(bus$postal_code)
bus$zip = substr(bus$zip, 1, 5)
table(bus$zip)
```



Check out some of the zips with only 1 record. Go online to confirm
that they are indeed zips in san francisco
some of these are 94188 

List 3-4 zip codes that are not in San Francisco. Where are they?

Text Answer
Answer
# 94545 - Hayward, look at record and see it's vending machine company with many locations
# 94602 - Oakland, look at the record and see it's a type and should be 94102
# 94609 - Oakland, look and find it is a chain with one loc in OAK
# 94621 - Alameda, 
# 95105

Check the zip code 94602. Where is it. Look in the business file to find 
the name and address of the restaurant with this zip code. Can you correct this zip code? 


Often want to clean the data. This might include, changing values and or dropping records. 

Are there many missing zip codes?
Look at the records for some of the "" zips. 
Some of these are off the grid.
Some of them are also missing values for longitude and latitude.

### How many businesses are missing lon and lat values?

```{r}
sum(is.na(bus$longitude))
```


Do some zip codes have more than their fair share of missing lat/lon values?

Let's reduce our comparison to just those zips that are in SF and 
that have many businesses. Below is a list of zip codes. 


```{r}
validZip = c("94102", "94103", "94104", "94105", "94107",
"94108", "94109", "94110", "94111", "94112", "94114","94115",
"94116", "94117", "94118", "94121", "94122", "94123", "94124",
"94127", "94131", "94132", "94133", "94134")
```

For these zip codes find the number of businesses with and without lat and lon values.

```{r}
busR = bus[bus$zip %in% validZip, ]
checkNAdist = table(busR$zip, is.na(busR$longitude))
```

For each zip code compute the expected number of businesses with and without lat lon values, under the assumption that all of the zips have the same amount of missingness as the city.

```{r}

```

How do we compare the observed number of businesses and the expected number of businesses?

We can make plots.  Make a plot of O - E / root(E). Explain this in more detail.  (Give them the following code) Explain why we normalize by root expected.

```{r}
totCt = apply(checkNAdist, 1, sum)
propNA = (apply(checkNAdist, 2, sum)[2]) / sum(checkNAdist)
Ect = propNA * totCt
Oct = checkNAdist[,2]
plot(x = row.names(checkNAdist), y = (Oct - Ect)/sqrt(Ect),
     type = "h", lwd = 2)
abline(h=0)
```

In Data 8 you learned how to compare observed and expected counts to see if the obesrved was unusual. You turned the difference between the two tables into a single measure of discrepancy. We will also do this, but use a slightly different measure.

Give the formula for the chi-square.

Compute this value for our observed data
```{r}

```

Is this an unusually large vvalue? We need to know what values this statistic might take on assuming that the missing lat/lon for businesses in zip codes behave like the whole city.

```{r}
#Give them code to run this simulation
```

Let's look at the distribution of values....

```{r}
#Tell them to refer to the notebook from Tuesday's class to plot
# the distribution and add their particular value to the plot
```


## Investigate the inspection data

As with the business data, find the name of the variables and the number of records and assess whether ther eis one record for each business.

```{r}

```


### the type variable?

Examine the type variable
```{r}
table(ins$type)
```

All have the same value, "routine",  except one record. 


### the date variable

I don't know if this is an issue in python.

```{r}
library(dplyr)
ins$newDate = as.Date(as.character(ins$date), "%Y%m%d")
```


Extract the year and create a new variable called year

```{r}
ins$year = format(ins$newDate,"%Y")
```



What range of years is covered in this data set?
Are there roughly same number of inspections each year?

```{r}
table(ins$year)
```

Answer:
No, 2013 only has a few. Also 2015 has far fewer than 2014 or 2016.

Let's examine only the inspections for one year, 2016. This puts restaurants on a more equal footing because...

```{r}
ins2016 = ins[ins$year == 2016, ]
```



### Explore inspection score

What does the distribution of inspection score for 2016 look like?


```{r}
scoreCts = table(ins2016$score)
plot(scoreCts, type = "h")
```

Describe in words

Text answer
The distribution is skewed left (as expected with a variable bounded on the right)
The distribution looks a bit bumpy with even numbers having higher counts than odd

Is there one inspection per business? How many restaurants had 
two inspections? three inspections?

```{r}
length(unique(ins2016$business_id))
table(table(ins2016$business_id))
```


Some restaurants had 3 inspections in a calandar year

### inspection and business data

Let's reexamine the distribution of score when each restaurant is represented by one score. Which score should we use? The earliers, lowest, average?

We should pick one 

Let's also create a new variable which is the number of inspections that each restaurant had. 

Can we add these new variables to the business data set?

We can use business_id to do this.

The following does not do that. It keeps the first and last score and the date of the score.  The code is clunky...

```{r}
id = unique(ins2016$business_id)
n = length(id)
firstDate = rep(as.Date("20000101", "%Y%m%d"), n) 
firstScore = vector(mode="numeric", length =n) 
lastDate = rep(as.Date("20000101", "%Y%m%d"), n) 
lastScore = vector(mode="numeric", length = n) 
numIns = rep(1, length(id))

ins1 = data.frame(id, firstDate, firstScore, 
                  lastDate, lastScore, numIns)
row.names(ins1) = id

for (i in id ) {
  one = ins2016[ ins2016$business_id == i, ]
  dates = one[ , "newDate"]
  scores = one[ , "score"]
  minI = which.min(dates)
  maxI = which.max(dates)
  ins1[ins1$id == i, "firstDate"] = dates[minI]
  ins1[ins1$id == i, "firstScore"] = scores[minI]
  if (nrow(one) > 1) {
    ins1[ins1$id == i, "lastScore"] = scores[maxI]
    ins1[ins1$id == i, "lastDate"] = dates[maxI]
    ins1[ins1$id == i, "numIns"] = nrow(one)
  }
}

ins1[ins1$numIns == 1, "lastScore"] = NA
ins1[ins1$numIns == 1, "lastDate"] = NA

```


### Restaurants with multiple inspections

What's the relationship between the first and second scores for the businesses with 2 inspections in a year? Do they typically improve?
Make a scatter plot to display these pairs of scores

```{r}
ins2 = ins1[ins1$numIns == 2, ]

plot(ins2$lastScore ~ ins2$firstScore,
     xlim = c(60, 100), yli = c(60, 100))
abline(a=0, b=1, col='red', lwd = 2)
```

Make a histogram of the difference in the scores.

```{r}
hist(ins2$lastScore - ins2$firstScore, breaks = 30)
summary(ins2$lastScore - ins2$firstScore)
```


Interestingly, the second inspection often is worse than first


## Violations Data

Read the file and 
display the first 10 records from the 

```{r}
head(vio, 10)
```

Just looking at the first few records we see that each inspection
has multiple entries, some entries are repeated.
if corrected, a date is listed in the description.
This date seems to be the same date as the inspection...

Fix the date for this and restrict to just inspections in 2016.

```{r}
vio$newDate = as.Date(as.character(vio$date), "%Y%m%d")
vio$year = format(vio$newDate,"%Y")
vio2016 = vio[ vio$year == 2016, ]
```


### Number of violations

Derive a variable, numVio, that contains the number of violations in a restaurant inspection
                   
```{r}
numVio = aggregate(vio2016$date, by = list(vio2016$business_id), 
                   function(x) length(x)/length(unique(x)))$x
```

What is the distribution of numVio? Make a histogram and describe its shape.


```{r}
summary(numVio)
hist(numVio, breaks = seq(0.5, 11.5, by =1))
```


Distribution is right skewed


# EXTRA

The following code is for your (GSI) interest. We will discuss in class.
Or, we may wnat to give them this code and ask them to interpret the 
results

Roll up to restaurant level and count the number of violations,
and the number corrected.

```{r}
corrected = grepl("\\[", vio2016$description)

numCorr = aggregate(vio2016$date, by = list(vio2016$business_id), 
                   function(x) length(x)/length(unique(x)))$x
```


Make the violations more similar by dropping the [date fixed] clause

```{r}
vio2016$desc2 = sub("\\[.*\\]", "", vio2016$description)
vio2016$desc2 = sub("[[:blank:]]+$", "", vio2016$desc2)
vio2016$desc2 = tolower(vio2016$desc2)
```



Collate and examine the top 20

```{r}
vioTable = table(vio2016$desc2)
head(sort(vioTable, decreasing = TRUE), 25)
tail(sort(vioTable, decreasing = TRUE), 25)
```



There are 64 violations.
Derive variable for whether or not a certain type of violation occurred.

```{r}
unclean = grepl("unsanitary", vio2016$desc2) | 
  grepl("unclean", vio2016$desc2) |
  grepl("clean", vio2016$desc2)

human = grepl("hands", vio2016$desc2) | 
  grepl("hair", vio2016$desc2) |
  grepl("", vio2016$desc2)

surface = grepl("floor", vio2016$desc2) |
  grepl("surface", vio2016$desc2) |
  grepl("wall", vio2016$desc2)

food = grepl("food", vio2016$desc2) | 
  grepl("fish", vio2016$desc2) |
  grepl("oyster", vio2016$desc2) 

vermin = grepl("vermin", vio2016$desc2)

facilities = grepl("facilities", vio2016$desc2) |
  grepl("sewage", vio2016$desc2) | 
  grepl("plumbing", vio2016$desc2) 

methods = grepl("method", vio2016$desc2) | 
  grepl("thermometer", vio2016$desc2) 

highRisk = grepl("high", vio2016$desc2)

vio2016b = data.frame(unclean, human, surface, food, vermin, facilities,
                      methods, highRisk)

aggVio = aggregate(vio2016b, by = list(vio2016$business_id), any)
aggVio$numVio = numVio
names(aggVio) = c("id", names(aggVio)[-1])

```



Merge this file with the inspection file

```{r}
insPlus = merge(x = ins1, y = aggVio, by = "id", all = TRUE)
```

Note that some restaurants were inspected and no violations listed,
even when the score is not perfect.

Will want to fill in the violation variables, especially the numVio should 
be set to 0. Should the logicals be set to FALSE?

```{r}
insPlus[ is.na(insPlus$numVio), 
         c("unclean", "human", "surface", "food", "vermin", 
           "facilities", "methods", "highRisk")] = FALSE

insPlus[ is.na(insPlus$numVio), "numVio"] = 0
```


A scatter plot of the score and number of violations for 
restaurants with multiple violations

```{r}
plot(jitter(firstScore, 2) ~ jitter(numVio, 2), data = insPlus)
cor(insPlus$numVio, insPlus$firstScore, use = "complete")
```



Are some violations more costly than others?

```{r}
boxplot(firstScore ~ unclean + vermin, data = insPlus)
boxplot(firstScore ~ food + human, data = insPlus)
boxplot(firstScore ~ methods + surface, data = insPlus)
```


Use the type of violation to describe the score

```{r}
lm(firstScore ~ unclean + vermin + human + food + surface + methods + highRisk + facilities, data = insPlus)

```

Explain what the coefficients mean

Arrange in order of median score for violation

```{r}
par(mfrow = c(2,4), mar = c(1,3,2,1))
boxplot(firstScore ~ methods, data = insPlus)
boxplot(firstScore ~ highRisk, data = insPlus)
boxplot(firstScore ~ food, data = insPlus)
boxplot(firstScore ~ vermin, data = insPlus)
boxplot(firstScore ~ unclean, data = insPlus)
boxplot(firstScore ~ surface, data = insPlus)
boxplot(firstScore ~ human, data = insPlus)
```




