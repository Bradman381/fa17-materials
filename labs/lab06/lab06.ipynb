{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Modeling and Estimation\n",
    "\n",
    "** If you are not attending lab, this assignment is due 10/03/2017 at 11:59pm (graded on accuracy) **\n",
    "\n",
    "** If you are attending lab, you do not need to submit the assignment; you just need to get checked off by your TA. **\n",
    "\n",
    "In this lab we will work through the process of:\n",
    "1. implementing a basic model, defining loss functions, \n",
    "1. minimizing loss functions using numeric libraries, and \n",
    "1. finally bootstrap sampling to understand the variability in the parameter estimates.\n",
    "\n",
    "This lab will continue using the toy tip calculation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "33c63379-d85b-4638-8183-d008fdb96de7",
    "_uuid": "7ad7f9f24df7dba8ac92d234890835f6b9970834",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines load the tests.\n",
    "# !pip install -U okpy\n",
    "\n",
    "from IPython.display import display, Latex, Markdown\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab06.ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ok.auth(force=True)\n",
    "ok.auth(force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Tips Dataset\n",
    "\n",
    "To begin with, we load the tips dataset from the `seaborn` library.  The tips data contains records of tips, total bill, and information about the person who paid the bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sns.load_dataset(\"tips\")\n",
    "\n",
    "print(\"Number of Records:\", len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br></br>\n",
    "\n",
    "# Question 1: Defining the Model \n",
    "\n",
    "In lecture we modeled the percent tip.  In this lab we will instead attempt to model the tip value (in dollars) as a function of the total bill.  As a consequence we define the following mathematical model:\n",
    "\n",
    "$$\\Large\n",
    "\\texttt{Tip} = \\theta^*  \\times \\texttt{TotalBill}\n",
    "$$\n",
    "\n",
    "This follows the similar intuition that tips are some **unknown** percentage of the total bill.  We will then try to estimate the slope of this relationship which corresponds to the percent tip.\n",
    "\n",
    "Here the parameter $\\theta^*$ represents the true percent tip that we would like to estimate.  \n",
    "\n",
    "**Implement the python function for this model (yes this is very easy):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def model(theta, total_bill):\n",
    "    \"\"\"\n",
    "    Takes the parameter theta and the total bill returns the computed tip.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q01a"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q01a')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/><br/>\n",
    "\n",
    "# Loss Functions\n",
    "\n",
    "In class we covered a range of different loss functions.  In this lab we will implement the squared loss and the absolute loss functions.  \n",
    "Suppose for a given total bill $x$ we observe a tip value of $y$ and our model predicts:\n",
    "$$\\Large\n",
    "% the \\hspace{0pt} is added to address a bug in safari mathjax\n",
    "\\hat{\\hspace{0pt}y} = \\theta * x\n",
    "$$ \n",
    "then any of the following might be appropriate **loss functions**\n",
    "\n",
    "1. **Squared Loss** (also known as the $L^2$ loss pronounced \"ell-two\"):\n",
    "$$\\Large\n",
    "% the \\hspace{0pt} is added to address a bug in safari mathjax\n",
    "L\\left(y, \\hat{\\hspace{0pt}y} \\right) = \\left( y - \\hat{\\hspace{0pt}y} \\right)^2\n",
    "$$\n",
    "1. **Absolute Loss** (also known as the $L^1$ loss pronounced \"ell-one\"):\n",
    "$$\\Large\n",
    "% the \\hspace{0pt} is added to address a bug in safari mathjax\n",
    "L\\left(y, \\hat{\\hspace{0pt}y} \\right) = \\left| y - \\hat{\\hspace{0pt}y} \\right|\n",
    "$$\n",
    "\n",
    "---\n",
    "<br></br>\n",
    "In this question, you are going to define functions for **squared loss** and **absolute loss**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2a: \n",
    "\n",
    "Implement the squared loss function:\n",
    "$$\\Large\n",
    "L\\left(y, \\hat{\\hspace{0pt}y} \\right) = \\left( y - \\hat{\\hspace{0pt}y} \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def squared_loss(y_obs, y_hat):\n",
    "    \"\"\"\n",
    "    y_obs: an array of observed valued\n",
    "    y_hat: an array of predicted values\n",
    "    return an array corresponding to the loss for each prediction\n",
    "    \"\"\"\n",
    "    ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02a"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q02a')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2b:\n",
    "\n",
    "Suppose you observe $y=3.00$ and $x=28.00$ using the `model` and `squared_loss` function defined above plot the loss for a range of $\\theta$ values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([3.00])\n",
    "x = np.array([28.00])\n",
    "thetas = np.linspace(0, 0.3, 200) # A range of theta values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "## Finish this by replacing 0.0 with the correct calculation \n",
    "## Hint 1: You will use squared_loss y, model, theta and x\n",
    "## Hint 2: You might need to extract a single value from an array (or take the mean)\n",
    "loss = np.array([ 0.0 for theta in thetas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02b"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q02b')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following should produce this picture:\n",
    "\n",
    "![loss_curve.png](squared_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(thetas, loss, label=\"Squared Loss\")\n",
    "plt.xlabel(r\"Choice for $\\theta$\")\n",
    "plt.ylabel(r\"Loss\")\n",
    "plt.legend(loc=4)\n",
    "plt.savefig(\"squared_loss_my_plot.png\",  bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2c:\n",
    "Implement the absolute loss \n",
    "$$\\Large\n",
    "L\\left(y, \\hat{\\hspace{0pt}y} \\right) = \\left| y - \\hat{\\hspace{0pt}y} \\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def abs_loss(y_obs, y_hat):\n",
    "    \"\"\"\n",
    "    y_obs: an array of observed valued\n",
    "    y_hat: an array of predicted values\n",
    "    return an array corresponding to the loss for each prediction\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q02c"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q02c')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the plot of the absolute loss.  If you implemented things correctly it should look like:\n",
    "\n",
    "![absolute loss](absolute_loss.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "y = np.array([3.00])\n",
    "x = np.array([28.00])\n",
    "thetas = np.linspace(0, 0.3, 200) \n",
    "\n",
    "# Code provided for you this time. (your welcome)\n",
    "loss = np.array([abs_loss(y, model(theta,x)).mean() for theta in thetas])\n",
    "\n",
    "plt.plot(thetas, loss, label=\"Absolute Loss\")\n",
    "plt.xlabel(r\"Choice for $\\theta$\")\n",
    "plt.ylabel(r\"Loss\")\n",
    "plt.legend(loc=4)\n",
    "plt.savefig(\"absolute_loss_my_plot.png\",  bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2d: Plotting **Average Loss** for our Data\n",
    "\n",
    "We can extend the above loss functions to an entire dataset by taking the average. Let the dataset $\\mathcal{D}$ be the set of observations:\n",
    "\n",
    "$$\\Large\n",
    "\\mathcal{D} = \\{(x_1, y_1), \\ldots, (x_n, y_n)\\}\n",
    "$$\n",
    "\n",
    "where $x_i$ is the total bill and $y_i$ is the tip dollar amount.\n",
    "\n",
    "We can define the average loss over the dataset as:\n",
    "\n",
    "$$\\Large\n",
    "L\\left(\\theta, \\mathcal{D}\\right) = \\frac{1}{n} \\sum_{i=1}^n L(m_\\theta(x_i), y_i) = \\frac{1}{n} \\sum_{i=1}^n L(\\theta *  x_i, y_i)\n",
    "$$\n",
    "\n",
    "where $m_\\theta(x_i) = \\theta * x_i$ is the model evaluated using the parameters $\\theta$ on the bill amount $x_i$.\n",
    "\n",
    "**Complete the following code block to render a plot of the average absolute and squared loss for different values of $\\theta$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "thetas = np.linspace(0, 0.3, 200) # A range of theta values:\n",
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "\n",
    "# Replace 0.0 with the correct value computed \n",
    "# using the model and loss functions from above\n",
    "avg_squared_loss = np.array([0.0 for theta in thetas])\n",
    "avg_absolute_loss = np.array([0.0 for theta in thetas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly the following plot should look like:\n",
    "\n",
    "![Average Loss](average_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(thetas, avg_squared_loss, label = \"Average Squared Loss\")\n",
    "plt.plot(thetas, avg_absolute_loss, label = \"Average Absolute Loss\")\n",
    "plt.xlabel(r\"$\\theta$ Value\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.savefig(\"average_loss_my_plot.png\",  bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/><br/> \n",
    "\n",
    "# Question 3: Minimizing The Loss\n",
    "\n",
    "In some cases, it is possible to use calculus to analytically compute the parameters $\\theta$ that minimize the loss function.  However, in this lab we will use computational techniques to minimize the loss.  Here we will use the [`scipy.optimize.minimize`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) routine to minimize the average loss.\n",
    "\n",
    "Complete the following python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def minimize_average_loss(loss_function, model, x, y):\n",
    "    \"\"\"\n",
    "    loss_function: either the squared or absolute loss functions from above.\n",
    "    model: the model (as defined above)\n",
    "    x: the x values (total bills)\n",
    "    y: the y values (tip amounts)\n",
    "    return the estimate for theta as a scalar\n",
    "    \n",
    "    Note we will ignore failed convergence for this lab ... \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Notes on the following function call which you need to finish:\n",
    "    # \n",
    "    # 0. the ... should be replaced with the average loss evaluated on \n",
    "    #       the data x, y using the model and appropriate loss function\n",
    "    # 1. x0 is the initial value for THETA.  Yes, this is confusing\n",
    "    #       but optimization people like x to be the thing they are \n",
    "    #       optimizing.\n",
    "    # 2. We extract the 'x' entry in the dictionary which corresponds\n",
    "    #       to the value of theta at the optimum\n",
    "    # 3. The resulting theta is actually an array with a single element\n",
    "    #       therefore we grab just that element with [0]\n",
    "    \n",
    "    return minimize(lambda theta: ..., x0=0.0)['x'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Should be roughly 0.1437\n",
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "minimize_average_loss(squared_loss, model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Should be roughly 0.1496\n",
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "minimize_average_loss(abs_loss, model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q03"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q03')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br/><br/><br/> \n",
    "\n",
    "# Question 4: Simulation\n",
    "\n",
    "In this question we will use the bootstrap procedure to estimate the distribution of loss minimizing estimators.  \n",
    "\n",
    "At a high level the bootstrap algorithm is:\n",
    "\n",
    "```\n",
    "samples = []\n",
    "\n",
    "for i in nsamples:\n",
    "\n",
    "    n = len(data)\n",
    "\n",
    "    data_sample = draw sample n samples WITH REPLACEMENT from the data (both x and y)\n",
    "    \n",
    "    sample_theta_opt = estimate theta on data_sample\n",
    "    \n",
    "    samples.append( sample_theta_opt )\n",
    "    \n",
    "\n",
    "sns.distplot(samples)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4a \n",
    "\n",
    "To use `bootstrap`, we need to repeatedly draw samples. We give you the code for the bootstrap:\n",
    "\n",
    "```python\n",
    "def bootstrap(loss_function, model, x, y, nsamples=1000):\n",
    "    samples = []\n",
    "    for i in range(nsamples):\n",
    "        samples.append(sample_theta(loss_function, model, x, y))\n",
    "    return samples \n",
    "```\n",
    "\n",
    "However, you will need to implement the `sample_theta()` function which should:\n",
    "\n",
    "1. resample the data with replacement.\n",
    "    * **hint 1:** check out [`np.random.randint`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.randint.html)\n",
    "    * **hint 2:** consider something like:\n",
    "        ```python\n",
    "        x = np.array([1,2,3])\n",
    "        y = np.array([1,2,3])\n",
    "        ind = np.random.randint(0, 3, 3)\n",
    "        print(x[ind], y[ind])\n",
    "        ```\n",
    "1. call the loss minimization routine (from above) to estimate $\\theta$ on the sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "def sample_theta(loss_function, model, x, y):\n",
    "    \"\"\"\n",
    "    loss_function: either the squared or absolute loss function\n",
    "    model: the predictive model as defined above\n",
    "    x: the total bill as defined above\n",
    "    y: the tip value as defined above\n",
    "    returns a single theta estimate for a random resampling of the data \n",
    "    \"\"\"\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap(loss_function, model, x, y, nsamples=1000):\n",
    "    samples = []\n",
    "    print_mod = int(nsamples/10.0)\n",
    "    for i in range(nsamples):\n",
    "        if (i+1) % print_mod == 0:\n",
    "            print(\"Generating Sample\", i+1, \"out of\", nsamples, \"samples.\")\n",
    "        samples.append(sample_theta(loss_function, model, x, y))\n",
    "    return samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4b \n",
    "\n",
    "Using `bootstrap()` function to generate 1000 samples for **squared loss** and **absolute loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapped Squared Loss\n",
    "\n",
    "Call the above `bootstrap` function using the `squared_loss`, `model`, `x`, and `y` for 1000 samples.  This may take up to a minute to complete.  If you are debugging your implementation you may try running fewer samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "squared_loss_samples = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly the following plot should **approximately** look like:\n",
    "\n",
    "![squared_loss_samples](squared_loss_samples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "sns.distplot(squared_loss_samples)\n",
    "plt.xlabel(r\"Estimated $\\theta$\")\n",
    "print(\"Sample SD:\", np.std(squared_loss_samples))\n",
    "print('Sample MEAN:', np.mean(squared_loss_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapped Absolute Loss \n",
    "\n",
    "Call the above `bootstrap` function using the `absolute_loss`, `model`, `x`, and `y` for 1000 samples.  **This may take a few minutes to complete.**  If you are debugging your implementation you may try running fewer samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "y = data['tip']\n",
    "x = data['total_bill']\n",
    "abs_loss_samples = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If done correctly the following plot should **approximately** look like:\n",
    "\n",
    "![abs_loss_samples](abs_loss_samples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(abs_loss_samples)\n",
    "plt.xlabel(r\"Estimated $\\theta$\")\n",
    "print(\"Sample SD:\", np.std(abs_loss_samples))\n",
    "print(\"Sample MEAN:\", np.mean(abs_loss_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q04b"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q04b')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4c:\n",
    "\n",
    "Which loss function has lower variability and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student",
     "written"
    ]
   },
   "outputs": [],
   "source": [
    "question4c_answer = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Congrats! You are finished with this assignment. For convenience, we've included a cell below that runs all the OkPy tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"ok_tests\") if q.startswith('q')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to submit your assignment to OkPy. The autograder should email you shortly with your autograded score. The autograder will only run once every 30 minutes.\n",
    "\n",
    "**If you're failing tests on the autograder but pass them locally**, you should simulate the autograder by doing the following:\n",
    "\n",
    "1. In the top menu, click Kernel -> Restart and Run all.\n",
    "2. Run the cell above to run each OkPy test.\n",
    "\n",
    "**You must make sure that you pass all the tests when running steps 1 and 2 in order.** If you are still failing autograder tests, you should double check your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "301px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}